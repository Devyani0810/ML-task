{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Level 1"
      ],
      "metadata": {
        "id": "PtRRXX5oYW8T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIKF-J5SVsaJ",
        "outputId": "12bc0816-e30c-47dc-cb37-7222daf44cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.7-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.59)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.4.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.9/154.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading langgraph_checkpoint-2.0.26-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.1-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, python-dotenv, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.10 langgraph-0.4.7 langgraph-checkpoint-2.0.26 langgraph-prebuilt-0.2.1 langgraph-sdk-0.1.70 ormsgpack-1.9.1 python-dotenv-1.1.0\n"
          ]
        }
      ],
      "source": [
        "# Install ALL required packages\n",
        "!pip install langgraph langchain-google-genai google-generativeai langchain_core python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0S7tzAkV-I2",
        "outputId": "1d41a377-0256-4a58-da26-c36f8499a4af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.7)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.59)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.26)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.1)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.4)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
            "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.9.1)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core>=0.1->langgraph) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain_core.messages import HumanMessage,AIMessage\n",
        "import operator\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"API kEy \" #gemini api\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-04-17\")\n",
        "\n",
        "\n",
        "def calculate(expr: str) -> str:\n",
        "    try:\n",
        "        return str(eval(expr))\n",
        "    except:\n",
        "        return \"Error\"\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[Union[HumanMessage, AIMessage]], operator.add]\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "\n",
        "workflow.add_node(\"chatbot\")\n",
        "workflow.set_entry_point(\"chatbot\")\n",
        "workflow.add_edge(\"chatbot\", \"end\")\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"MATH TEST:\")\n",
        "math_response = app.invoke({\"messages\": [HumanMessage(content=\"Calculate (12 + 5) * 3\")]})\n",
        "print(math_response[\"messages\"][-1].content)\n",
        "\n",
        "print(\"\\nCHAT TEST:\")\n",
        "chat_response = app.invoke({\"messages\": [HumanMessage(content=\"Hello! What can you do?\")]})\n",
        "print(chat_response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "IPFKxFfwWARb",
        "outputId": "a325eccb-d66f-4d6c-9c21-261c2042e289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-760b8a11dc34>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chatbot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_entry_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chatbot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chatbot\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langgraph/graph/state.py\u001b[0m in \u001b[0;36madd_node\u001b[0;34m(self, node, action, defer, metadata, input, retry, cache_policy, destinations)\u001b[0m\n\u001b[1;32m    372\u001b[0m                 )\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Node `{node}` already present.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, START\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import operator\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"API\" #gemini API key\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-04-17\")\n",
        "\n",
        "\n",
        "\n",
        "def calculate(expr: str) -> str:\n",
        "    try:\n",
        "        return str(eval(expr))\n",
        "    except:\n",
        "        return \"Error\"\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[Union[HumanMessage, AIMessage]], operator.add]\n",
        "\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "\n",
        "workflow.add_node(\"chatbot\", chatbot_node)\n",
        "workflow.set_entry_point(\"chatbot\")\n",
        "workflow.add_edge(\"chatbot\", END)\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"MATH TEST:\")\n",
        "math_response = app.invoke({\"messages\": [HumanMessage(content=\"Calculate (12 + 5) * 3\")]})\n",
        "print(math_response[\"messages\"][-1].content)\n",
        "\n",
        "print(\"\\nCHAT TEST:\")\n",
        "chat_response = app.invoke({\"messages\": [HumanMessage(content=\"Hello! What can you do?\")]})\n",
        "print(chat_response[\"messages\"][-1].content)\n",
        "\n"
      ],
      "metadata": {
        "id": "7CKccoKOWZVm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "08d1146d-59f9-4bd1-9d07-c259be7ca118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'State' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-8b58f5025aa2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mworkflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgentState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mworkflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'State' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import operator\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"API KEY\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-04-17\")\n",
        "\n",
        "\n",
        "\n",
        "def calculate(expr: str) -> str:\n",
        "    try:\n",
        "        return str(eval(expr))\n",
        "    except:\n",
        "        return \"Error\"\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[Union[HumanMessage, AIMessage]], operator.add]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "workflow = StateGraph(State)\n",
        "\n",
        "\n",
        "\n",
        "workflow.add_node(\"chatbot\", chatbot_node)\n",
        "workflow.set_entry_point(\"chatbot\")\n",
        "workflow.add_edge(\"chatbot\", END)\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"MATH TEST:\")\n",
        "math_response = app.invoke({\"messages\": [HumanMessage(content=\"Calculate (12 + 5) * 3\")]})\n",
        "print(math_response[\"messages\"][-1].content)\n",
        "\n",
        "print(\"\\nCHAT TEST:\")\n",
        "chat_response = app.invoke({\"messages\": [HumanMessage(content=\"Hello! What can you do?\")]})\n",
        "print(chat_response[\"messages\"][-1].content)\n",
        "\n"
      ],
      "metadata": {
        "id": "uW_rKXRtqaen",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "cc65a204-b9f4-43b9-d91d-11c831ddb4f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'State' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-489e39c711a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mworkflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAgentState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mworkflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStateGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mState\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'State' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Final Final Code\n",
        "# Basic imports\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import Graph, END\n",
        "from langchain_core.messages import HumanMessage\n",
        "import os\n",
        "\n",
        "# Set up\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"API KEY\"\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-preview-04-17\")\n",
        "\n",
        "#CALCULATOR TOOL\n",
        "\n",
        "def calculate(expr: str) -> str:   # Simple eval() - works for basic expressions\n",
        "    try:\n",
        "        return str(eval(expr))\n",
        "    except:\n",
        "        return \"Error\"    # Basic error message\n",
        "# GRAPH CONSTRUCTION\n",
        "workflow = Graph()  # Create empty graph\n",
        "\n",
        "def chatbot_node(state):\n",
        "    last_message = state[\"messages\"][-1].content\n",
        "\n",
        "    if \"calculate\" in last_message.lower():\n",
        "        answer = calculate(last_message)\n",
        "        return {\"messages\": [HumanMessage(content=answer)]}\n",
        "\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "workflow.add_node(\"chatbot\", chatbot_node)\n",
        "workflow.set_entry_point(\"chatbot\")\n",
        "workflow.add_edge(\"chatbot\", END)\n",
        "\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"Trying a math problem:\")\n",
        "result = app.invoke({\"messages\": [HumanMessage(content=\"(12+3)/3\")]})\n",
        "print(\"Answer:\", result[\"messages\"][-1].content) # Should show \"5.0\"\n",
        "\n",
        "\n",
        "print(\"\\nCHAT TEST:\")\n",
        "chat_response = app.invoke({\"messages\": [HumanMessage(content=\"Hello! Who are you?\")]})\n",
        "print(chat_response[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-6xJjDjeYGr",
        "outputId": "ce433196-b160-4930-f77e-f01f0f4541a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying a math problem:\n",
            "Answer: To evaluate the expression (12+3)/3, follow the order of operations (PEMDAS/BODMAS):\n",
            "\n",
            "1.  **Parentheses:** Calculate the sum inside the parentheses first.\n",
            "    12 + 3 = 15\n",
            "\n",
            "2.  **Division:** Now divide the result by 3.\n",
            "    15 / 3 = 5\n",
            "\n",
            "So, (12+3)/3 = 5\n",
            "\n",
            "CHAT TEST:\n",
            "I am a large language model, trained by Google.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Level2"
      ],
      "metadata": {
        "id": "au_96hGClWN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weather_tool(location):\n",
        "    weather_data = {\n",
        "        \"Mumbai\": \"22°C rainy\",\n",
        "        \"New Delhi\": \"18°C sunny\",\n",
        "        \"paris\": \"20°C cloudy\"\n",
        "    }\n",
        "    return weather_data[location]\n",
        "\n",
        "def fashion_tool(city):\n",
        "    trends = {\n",
        "        \"Mumbai\": \"All black\",\n",
        "        \"Paris\": \"Coats\",\n",
        "        \"New Delhi\": \"Streetwear\"\n",
        "    }\n",
        "    return trends[city]\n",
        "\n",
        "def chatbot_node(state):\n",
        "    last_msg = state[\"messages\"][-1].content\n",
        "\n",
        "    if \"calculate\" in last_msg:\n",
        "        return {\"messages\": calculate(last_msg)}\n",
        "\n",
        "\n",
        "    elif \"weather\" in last_msg:\n",
        "        location = last_msg.split(\"in\")[1]\n",
        "        weather = weather_tool(location)\n",
        "        return {\"messages\": [AIMessage(content=weather)]}\n",
        "\n",
        "\n",
        "    elif \"fashion\" in last_msg:\n",
        "        city = last_msg.replace(\"fashion\")\n",
        "        trend = fashion_tool(city)\n",
        "        return {\"messages\": [AIMessage(content=trend)]}\n",
        "\n",
        "    else:\n",
        "        response = llm.invoke(last_msg)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "print(\"TESTS\")\n",
        "try:\n",
        "    # Test 1: Weather with no location\n",
        "    print(app.invoke({\"messages\": [HumanMessage(content=\"Weather\")]}))\n",
        "\n",
        "    # Test 2: Fashion with wrong case\n",
        "    print(app.invoke({\"messages\": [HumanMessage(content=\"Fashion in Mumbai\")]}))\n",
        "\n",
        "    # Test 3: Typo in command\n",
        "    print(app.invoke({\"messages\": [HumanMessage(content=\"Waether in New Delhi\")]}))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"{str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxz1wAogzljC",
        "outputId": "44c99d14-2dc5-47c9-ca6a-8c9911b4f30d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TESTS\n",
            "{'messages': [AIMessage(content=\"Okay, I can help with that!\\n\\nTo tell you the weather, I need to know **where** you would like the weather for.\\n\\nPlease tell me the **city and state (or country)** you're interested in, and I can give you the current conditions or a forecast.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--43aa1929-0638-4bcc-837d-e8c835229c61-0', usage_metadata={'input_tokens': 2, 'output_tokens': 60, 'total_tokens': 297, 'input_token_details': {'cache_read': 0}})]}\n",
            "{'messages': [AIMessage(content=\"Okay, let's talk about fashion in Mumbai! It's a dynamic, diverse, and ever-evolving scene that reflects the city's unique spirit.\\n\\nHere's a breakdown of key aspects of fashion in Mumbai:\\n\\n1.  **The Melting Pot:** Mumbai is a city of migrants from all over India and the world. This diversity is heavily reflected in its fashion. You see a blend of traditional Indian wear, global Western styles, and a lot of fusion.\\n\\n2.  **Climate Influence:** Mumbai's hot and humid climate (especially outside of the short winter) dictates a lot.\\n    *   **Fabrics:** Lightweight, breathable fabrics like cotton, linen, rayon, and georgette are popular.\\n    *   **Silhouettes:** Loose, comfortable fits are preferred for daily wear.\\n    *   **Monsoon:** The monsoon season (June to September) influences choices towards quick-drying materials, shorter hemlines, and practical footwear.\\n\\n3.  **Bollywood's Impact:** As the heart of the Indian film industry, Bollywood has an enormous influence on Mumbai fashion.\\n    *   **Trends:** Styles seen on screen, red carpets, and worn by celebrities quickly become trends on the streets and in stores.\\n    *   **Glamour:** There's a strong element of glamour, especially for events, parties, and weddings, where elaborate traditional or Western outfits inspired by films are common.\\n\\n4.  **Fusion is Key:** One of the defining characteristics is the ease with which Mumbaians mix Indian and Western elements.\\n    *   **Examples:** Pairing a Kurti with jeans, wearing traditional jhumkas (earrings) with a Western dress, styling a saree with a contemporary blouse, or adding a Western jacket to an Indian outfit.\\n\\n5.  **Street Style vs. High Fashion:** Mumbai has both extremes.\\n    *   **Everyday/Street Style:** Practical, comfortable, and often trendy. Think casual Western wear (jeans, t-shirts, shorts, dresses), Kurtis with leggings/palazzos/pants, and simple, breezy outfits suitable for commuting and daily life.\\n    *   **Occasion Wear:** This is where the glamour comes out. Elaborate sarees, lehengas, Anarkalis, gowns, suits, and designer wear are common for weddings, festivals, and parties.\\n\\n6.  **Shopping Destinations:** Mumbai offers a range of shopping experiences:\\n    *   **Street Markets:** Famous ones like Colaba Causeway, Linking Road, and Fashion Street offer affordable, trendy clothes, accessories, and footwear where bargaining is key.\\n    *   **Malls:** Numerous large malls house a mix of international high-street brands and popular Indian brands.\\n    *   **Boutiques & Designer Stores:** Areas like Bandra, Kala Ghoda, and Palladium have high-end boutiques and flagship stores of renowned Indian designers.\\n    *   **Local Markets:** Specific areas might be known for textiles or particular types of traditional wear.\\n\\n7.  **Mumbai as a Fashion Hub:**\\n    *   It's home to many top Indian designers.\\n    *   It hosts major fashion events like Lakmé Fashion Week.\\n    *   It's a center for fashion education, modeling agencies, and the fashion industry in general.\\n\\n8.  **Current Trends (Always Evolving):** While trends change rapidly, some consistent themes include:\\n    *   Comfort and practicality remain important.\\n    *   Athleisure is popular for casual wear.\\n    *   Sustainable and ethical fashion are gaining traction.\\n    *   Bold prints, vibrant colors, and contemporary silhouettes are common.\\n    *   Personal expression is valued – people adapt trends to their own style.\\n\\nIn summary, fashion in Mumbai is a vibrant blend of tradition and modernity, heavily influenced by its climate, Bollywood, and diverse population. It's about comfort and practicality for daily life, mixed with bursts of high glamour for special occasions, and a constant exploration of fusion styles. It's less about a single uniform look and more about individual expression within a broad, dynamic framework.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--807a076f-c83c-4664-a414-95d18890f83a-0', usage_metadata={'input_tokens': 4, 'output_tokens': 857, 'total_tokens': 2163, 'input_token_details': {'cache_read': 0}})]}\n",
            "{'messages': [AIMessage(content='Okay, let me check the current weather in New Delhi for you.\\n\\nAs of [Current Time - e.g., late afternoon/early evening], the weather in New Delhi is typically:\\n\\n*   **Current Temperature:** Around **37-39°C** (This can vary slightly depending on the exact time and location within the city).\\n*   **Conditions:** Often **Hazy** or **Smoggy**.\\n*   **Feels Like:** It feels warmer, potentially in the **40-43°C** range due to humidity.\\n*   **Humidity:** Moderate, around **40-50%**.\\n*   **Wind:** Light breeze, usually from the West or Northwest.\\n\\nVisibility is likely reduced due to the haze/smog.\\n\\nPlease note that weather conditions can change. Would you like a forecast for the next few hours or days?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--169b164a-2f33-4fd8-a150-fc76911aa62b-0', usage_metadata={'input_tokens': 6, 'output_tokens': 185, 'total_tokens': 1244, 'input_token_details': {'cache_read': 0}})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def chatbot_node(state):\n",
        "    last_message = state[\"messages\"][-1].content.lower()\n",
        "\n",
        "\n",
        "    if \"weather\" in last_message:\n",
        "        location = last_message.replace(\"weather\", \"\").replace(\"in\", \"\").strip()\n",
        "        if not location:\n",
        "            location = \"New York\"\n",
        "        report = weather_tool(location)\n",
        "        return {\"messages\": [HumanMessage(content=report)]}\n",
        "\n",
        "    elif \"fashion\" in last_message or \"trend\" in last_message:\n",
        "        location = last_message.replace(\"fashion\", \"\").replace(\"trends\", \"\").replace(\"in\", \"\").strip()\n",
        "        if not location:\n",
        "            location = \"Paris\"\n",
        "        trends = fashion_tool(location)\n",
        "        return {\"messages\": [HumanMessage(content=trends)]}\n",
        "\n",
        "    else:\n",
        "        response = llm.invoke(state[\"messages\"])\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "print(\"\\n TEST 1: WEATHER \")\n",
        "weather_test = app.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"What's the weather in New Delhi?\")]\n",
        "})\n",
        "print(\"Weather Response:\", weather_test[\"messages\"][-1].content)\n",
        "\n",
        "print(\"\\nTEST 2: FASHION\")\n",
        "fashion_test = app.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Current fashion trends in Paris\")]\n",
        "})\n",
        "print(\"Fashion Response:\", fashion_test[\"messages\"][-1].content)\n",
        "\n",
        "print(\"\\nTEST 3: REGULAR CHAT\")\n",
        "chat_test = app.invoke({\n",
        "    \"messages\": [HumanMessage(content=\"Tell me a joke\")]\n",
        "})\n",
        "print(\"Chat Response:\", chat_test[\"messages\"][-1].content)"
      ],
      "metadata": {
        "id": "tA6yBAwkqPU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a5b6298-b6d7-4550-89e3-fe5e91a6f969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " TEST 1: WEATHER \n",
            "Weather Response: I cannot give you real-time, minute-by-minute weather updates as I don't have live access to constantly changing weather data feeds.\n",
            "\n",
            "However, I can look up the latest weather information available to me for New Delhi.\n",
            "\n",
            "Based on the most recent data I have access to, the weather in New Delhi is typically:\n",
            "\n",
            "*   **Temperature:** [Provide temperature in Celsius and/or Fahrenheit]\n",
            "*   **Conditions:** [e.g., Sunny, Partly Cloudy, Cloudy, Chance of Rain, etc.]\n",
            "*   **Other details (if available):** [e.g., Wind speed/direction, Humidity]\n",
            "\n",
            "**For the most current and accurate weather information right now, please check a reliable weather app, website (like AccuWeather, The Weather Channel, or the India Meteorological Department website), or perform a quick search on Google or Bing.**\n",
            "\n",
            "TEST 2: FASHION\n",
            "Fashion Response: Okay, let's talk about current fashion trends in Paris. It's important to remember that Parisian style is less about fleeting micro-trends and more about an *approach* to dressing – one that emphasizes timelessness, quality, and effortless chic. However, within that framework, certain silhouettes, pieces, and aesthetics are particularly popular right now.\n",
            "\n",
            "Here are some key elements of current Parisian fashion:\n",
            "\n",
            "1.  **The Reign of Relaxed Tailoring:**\n",
            "    *   **Oversized Blazers:** Still a huge staple. Worn over everything from t-shirts and jeans to slip dresses. They add structure and polish without feeling stiff.\n",
            "    *   **Wide-Leg Trousers:** High-waisted and wide-leg pants (in denim, wool, linen, or silk blends) are everywhere. They are comfortable, chic, and elongate the leg when paired with the right top and shoes.\n",
            "\n",
            "2.  **Understated Luxury & Quality Fabrics:**\n",
            "    *   **Quiet Luxury Influence:** The global trend of \"quiet luxury\" aligns perfectly with Parisian style. It's about high-quality fabrics (cashmere, silk, fine wool, linen, good cotton), impeccable fit, and minimal or no visible logos.\n",
            "    *   **Investment Pieces:** Parisians tend to invest in fewer, but better-made items that last for years. Think classic trench coats, perfect knitwear, and versatile leather goods.\n",
            "\n",
            "3.  **Effortless Essentials:**\n",
            "    *   **The Perfect White Shirt:** Crisp, slightly oversized, or classic fit – a well-fitting white button-down is a core piece. Worn tucked, untucked, or open over a top.\n",
            "    *   **Quality Knitwear:** Fine gauge cashmere sweaters, simple crewnecks, or elegant cardigans in neutral tones are essential for layering.\n",
            "    *   **Classic Denim:** Straight-leg or slight bootcut jeans in a medium to dark wash are preferred over overly distressed or trendy cuts.\n",
            "\n",
            "4.  **Midi Lengths:**\n",
            "    *   **Slip Skirts & Dresses:** Satin or silk slip skirts and dresses in neutral colors or simple patterns are very popular. They are incredibly versatile and can be dressed up or down.\n",
            "    *   **A-Line or Flowy Midi Skirts:** Comfortable and chic, often paired with simple tops or knitwear.\n",
            "\n",
            "5.  **Comfortable Yet Chic Footwear:**\n",
            "    *   **Ballet Flats:** The resurgence of ballet flats continues. They add a touch of femininity and are perfect for walking around the city.\n",
            "    *   **Loafers:** Classic leather loafers (sometimes slightly chunky) are a go-to for a polished yet comfortable look.\n",
            "    *   **Stylish Sneakers:** Clean, classic white sneakers (like Veja, Stan Smiths, or simple retro styles) are worn casually with almost anything.\n",
            "    *   **Heeled Boots:** Ankle boots or knee-high boots with a block or slim heel are popular for cooler weather.\n",
            "\n",
            "6.  **Minimalist Accessories:**\n",
            "    *   **Structured Leather Bags:** Medium-sized crossbody or shoulder bags in classic shapes and neutral colors (black, brown, camel) are favored over overly flashy or logo-heavy bags.\n",
            "    *   **Simple Gold Jewelry:** Delicate gold necklaces, rings, and hoop earrings are preferred over statement pieces. Layering is subtle.\n",
            "    *   **Classic Sunglasses:** Timeless shapes like cat-eye, round, or classic square frames.\n",
            "\n",
            "7.  **Color Palette:**\n",
            "    *   **Neutrals Dominance:** Beige, camel, black, white, grey, and navy form the core of the Parisian wardrobe.\n",
            "    *   **Subtle Pops:** While neutrals reign, you might see subtle pops of color, often in accessories or one key piece like a colored knit or a patterned scarf.\n",
            "\n",
            "**In Summary, the current Parisian fashion vibe is about:**\n",
            "\n",
            "*   **Effortless Polish:** Looking put-together without looking like you tried too hard.\n",
            "*   **Comfort Meets Chic:** Incorporating comfortable elements like relaxed fits and practical shoes without sacrificing style.\n",
            "*   **Focus on Fit and Fabric:** Clothes that fit well and are made from quality materials are paramount.\n",
            "*   **Versatility:** Pieces that can be mixed and matched easily for different occasions.\n",
            "*   **Understated Elegance:** Avoiding anything too flashy, trendy, or overtly branded.\n",
            "\n",
            "It's about building a wardrobe of versatile, high-quality pieces that reflect personal style rather than chasing every new trend.\n",
            "\n",
            "TEST 3: REGULAR CHAT\n",
            "Chat Response: Okay, here's one for you:\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Level 3"
      ],
      "metadata": {
        "id": "ybKyPc7Nzyoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conversation_history = []\n",
        "\n",
        "def chatbot_node(state):\n",
        "    global conversation_history\n",
        "\n",
        "    conversation_history.append(state)\n",
        "\n",
        "    last_msg = state[\"messages\"][-1].content.lower()\n",
        "\n",
        "    if \"calculate\" in last_msg:\n",
        "        expr = last_msg.replace(\"calculate\", \"\").strip()\n",
        "        return {\"messages\": [AIMessage(content=calculate(expr))]}\n",
        "    elif \"weather\" in last_msg:\n",
        "        location = last_msg.split(\"in\")[-1].strip()\n",
        "        if not location:\n",
        "            location = \"new york\"\n",
        "        return {\"messages\": [AIMessage(content=weather_tool(location))]}\n",
        "\n",
        "    elif \"fashion\" in last_msg or \"trend\" in last_msg:\n",
        "        location = last_msg.replace(\"fashion\", \"\").replace(\"trend\", \"\").strip()\n",
        "        return {\"messages\": [AIMessage(content=fashion_tool(location))]}\n",
        "\n",
        "    else:\n",
        "        response = llm.invoke([state[\"messages\"][-1]])\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "print(\"TEST 1\")\n",
        "test = app.invoke({\"messages\": [HumanMessage(content=\"Hi, my name is Alex\")]})\n",
        "test = app.invoke({\"messages\": [HumanMessage(content=\"What did I just say?\")]})\n",
        "print(test[\"messages\"][-1].content)\n",
        "\n",
        "print(\"\\nTEST 2\")\n",
        "test = app.invoke({\"messages\": [HumanMessage(content=\"How's the weather?\")]})\n",
        "print(test[\"messages\"][-1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULhVYnh9z1bu",
        "outputId": "23c3b470-20c2-415f-a483-a0d9b0e76d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEST 1\n",
            "You just said: \"What did I just say?\"\n",
            "\n",
            "TEST 2\n",
            "I can't tell you the weather *right where you are* unless you tell me your location!\n",
            "\n",
            "Please tell me the **city and state (or zip code)** you're interested in, and I can look up the current weather for you.\n",
            "\n",
            "Alternatively, you can quickly check a weather app or website for the most up-to-the-minute information for your exact spot.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Level 4"
      ],
      "metadata": {
        "id": "IiOPm-_91pE4"
      }
    }
  ]
}